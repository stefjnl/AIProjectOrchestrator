# US-007: Code Generation Service

## User Story
**As a** developer using the AI Project Orchestrator  
**I want** to generate working code implementations from approved user stories  
**So that** I can complete the full automation pipeline from ideas to functional code while practicing advanced AI model orchestration and code quality assessment

## Context
This is the fourth and final core stage of the AI orchestration pipeline, completing the vision of transforming high-level project ideas into working code. The service must integrate with all three upstream services (Requirements Analysis, Project Planning, Story Generation) while demonstrating sophisticated model routing, context management, and code quality validation.

**Learning Objective**: Practice evaluating complex service orchestration patterns, AI model selection logic, file I/O operations, and code quality assessment systems - critical skills for senior developer interviews.

## Acceptance Criteria

### Core Functionality
- [ ] **Four-Stage Dependency Validation**: Verify Requirements → Planning → Stories all approved before code generation
- [ ] **Intelligent Model Routing**: 
  - Claude Sonnet: Architecture decisions, complex business logic, interfaces
  - Qwen3-coder: CRUD operations, service implementations, data access
  - DeepSeek: Alternative implementations for comparison/validation
- [ ] **TDD Workflow Implementation**: Generate comprehensive unit tests first, then implementation code
- [ ] **Context Aggregation**: Combine approved context from all three upstream services with token optimization
- [ ] **File Management**: Create structured code artifacts with proper organization and downloadable packages

### Service Interface & Implementation
- [ ] **ICodeGenerationService Interface**: Define in Domain layer following established patterns:
  ```csharp
  Task<CodeGenerationResponse> GenerateCodeAsync(CodeGenerationRequest request, CancellationToken cancellationToken);
  Task<CodeGenerationStatus> GetStatusAsync(Guid codeGenerationId, CancellationToken cancellationToken);
  Task<CodeArtifactsResult> GetGeneratedCodeAsync(Guid codeGenerationId, CancellationToken cancellationToken);
  Task<bool> CanGenerateCodeAsync(Guid storyGenerationId, CancellationToken cancellationToken);
  ```
- [ ] **CodeGenerationService**: Application layer implementation with complete orchestration workflow
- [ ] **Service Registration**: Register in DI container with Scoped lifetime

### Domain Models
- [ ] **CodeGenerationRequest**: Input model with story generation ID, technical preferences, model preferences, quality requirements
- [ ] **CodeGenerationResponse**: Output model with artifacts summary, review ID, status, generated file count
- [ ] **CodeGenerationStatus**: Enum (Processing, PendingReview, Approved, Rejected, Failed, StoriesNotApproved)
- [ ] **CodeArtifact**: Individual code file with filename, content, file type, test coverage
- [ ] **CodeArtifactsResult**: Collection of artifacts with metadata and download information

### API Controller
- [ ] **CodeController**: REST API endpoints following established conventions:
  - `POST /api/code/generate` - Generate code from approved stories
  - `GET /api/code/{id}/status` - Check generation status
  - `GET /api/code/{id}/artifacts` - Retrieve generated code artifacts
  - `GET /api/code/can-generate/{storyGenerationId}` - Check if code can be generated
  - `GET /api/code/{id}/download` - Download code as ZIP package

### Extended Upstream Services
- [ ] **IStoryGenerationService Extension**: Add `GetApprovedStoriesAsync` method to retrieve approved user stories
- [ ] **Implementation Update**: Extend StoryGenerationService with story retrieval functionality

### Model-Specific Instructions
- [ ] **CodeGenerator_Claude.md**: Senior architect persona for complex architectural decisions, interfaces, business logic
- [ ] **CodeGenerator_Qwen3Coder.md**: CRUD specialist for service implementations, data access, API endpoints  
- [ ] **CodeGenerator_DeepSeek.md**: Alternative implementation provider for validation and comparison
- [ ] **Model Selection Logic**: Implement intelligent routing based on story complexity, technical requirements

### Quality Validation & File Management
- [ ] **Code Quality Validation**: Basic syntax checking, compilation verification, test coverage assessment
- [ ] **File Organization**: Structure artifacts by project area (Controllers, Services, Models, Tests)
- [ ] **Package Management**: Create downloadable ZIP packages with proper folder structure
- [ ] **Test Integration**: Ensure generated tests compile and can be executed

### Context Management
- [ ] **Multi-Service Context Aggregation**: Combine context from Requirements + Planning + Stories
- [ ] **Token Optimization**: Monitor combined context size and implement compression when needed
- [ ] **Context Relevance**: Filter and prioritize context based on story technical requirements
- [ ] **Size Monitoring**: Log context size warnings when approaching token limits

## Implementation Guidelines

### Service Orchestration Pattern (Follow Exactly)
1. **Input Validation**: Validate CodeGenerationRequest properties and required fields
2. **Four-Stage Dependency Validation**: 
   - Check Requirements Analysis approved
   - Check Project Planning approved  
   - Check Story Generation approved
   - Verify all services are properly linked
3. **Context Retrieval**: Call GetAnalysisResultsAsync, GetPlanningResultsAsync, GetApprovedStoriesAsync
4. **Model Selection**: Route stories to appropriate AI models based on complexity/type
5. **Instruction Loading**: Load model-specific instructions via IInstructionService
6. **AI Processing**: Generate tests first, then implementation code
7. **Artifact Management**: Structure and organize generated code files
8. **Quality Validation**: Basic compilation and syntax checking
9. **Review Submission**: Submit complete code package via IReviewService
10. **Status Tracking**: Maintain in-memory status with thread-safe operations

### Technical Architecture Requirements
- **Domain Layer**: Models, interfaces, enums only
- **Application Layer**: Service implementation, orchestration logic
- **Infrastructure Layer**: No changes required (use existing AI clients)
- **API Layer**: Controller implementation following established patterns
- **No Entity Framework Changes**: Use existing in-memory storage approach

### Model Routing Strategy
```csharp
// Pseudo-logic for intelligent routing
if (story.Complexity == High || story.Type == "Architecture")
    useModel = "Claude";
else if (story.Type == "CRUD" || story.Category == "Data Access")
    useModel = "Qwen3-coder";
else if (needsValidation || story.RequiresComparison)
    useModel = "DeepSeek";
```

### File Organization Pattern
```
Generated Code Package/
├── Controllers/
│   ├── {Entity}Controller.cs
│   └── {Entity}Controller.Tests.cs
├── Services/
│   ├── I{Service}Service.cs
│   ├── {Service}Service.cs
│   └── {Service}Service.Tests.cs
├── Models/
│   ├── {Model}.cs
│   └── {Model}.Tests.cs
└── README.md (generation summary)
```

## Testing Requirements

### Unit Tests (Minimum 12 Tests)
- [ ] **Input Validation**: Test required fields, minimum lengths, invalid values
- [ ] **Dependency Validation**: Test four-stage dependency checking logic
- [ ] **Context Aggregation**: Test multi-service context retrieval and combination
- [ ] **Model Selection**: Test intelligent routing logic for different story types
- [ ] **Error Scenarios**: Test missing dependencies, AI provider failures, validation errors
- [ ] **Status Tracking**: Test status transitions and thread-safe operations

### Integration Tests (Minimum 5 Tests)  
- [ ] **API Endpoint Availability**: Verify all endpoints respond correctly
- [ ] **End-to-End Workflow**: Test complete code generation workflow
- [ ] **File Management**: Test artifact creation and download functionality
- [ ] **Multi-Provider Integration**: Test different AI model routing
- [ ] **Error Handling**: Test graceful handling of upstream service failures

### Code Quality Assessment Practice
- [ ] **Interface Design Review**: Evaluate single responsibility, async patterns, dependency management
- [ ] **Service Composition Analysis**: Assess multi-stage orchestration complexity
- [ ] **Error Handling Evaluation**: Review exception hierarchies and structured logging
- [ ] **Resource Management**: Analyze proper disposal patterns and memory usage
- [ ] **Concurrency Assessment**: Evaluate thread safety and async operation handling

## Definition of Done
- [ ] `ICodeGenerationService` interface defined in Domain layer with complete method signatures
- [ ] `CodeGenerationService` implementation in Application layer with full orchestration workflow
- [ ] Extended `IStoryGenerationService` with `GetApprovedStoriesAsync` method
- [ ] `CodeController` with all required REST endpoints following established conventions
- [ ] Service registered in DI container with proper lifetime management
- [ ] Three model-specific instruction files created with comprehensive guidance
- [ ] Unit tests written and passing (minimum 12 tests)
- [ ] Integration tests demonstrate end-to-end functionality (minimum 5 tests)
- [ ] All existing tests continue to pass (101/101 baseline maintained)
- [ ] Code builds without warnings or errors
- [ ] Basic file management and download functionality operational
- [ ] Context aggregation working with token size monitoring
- [ ] Error logging implemented with structured logging and correlation IDs

## Technical Constraints & Architecture Compliance

### Clean Architecture Requirements
- **Domain Layer**: Only interfaces, models, enums - no implementation logic
- **Application Layer**: Service implementation, orchestration, business rules
- **No Infrastructure Changes**: Use existing AI client infrastructure without modification
- **API Layer**: Controller only - no business logic

### Integration Requirements  
- **Use Existing Components**: Leverage IInstructionService, IAIClientFactory, IReviewService exactly as implemented
- **Follow Established Patterns**: Match RequirementsAnalysisService, ProjectPlanningService, StoryGenerationService implementation patterns
- **Maintain Consistency**: Use same error handling, logging, and validation approaches
- **Preserve Quality**: All existing functionality must continue working unchanged

## Out of Scope (Future Enhancements)
- Advanced code quality metrics (cyclomatic complexity, maintainability index)
- Code compilation and execution testing
- Integration with version control systems
- Advanced file template management
- Performance optimization and caching
- Real-time collaboration features
- Advanced context compression algorithms

## Success Validation Criteria

### Technical Achievement
- Complete four-stage AI orchestration pipeline operational
- Intelligent model routing working with multiple providers
- TDD workflow generating tests before implementation
- File management with downloadable packages
- Quality validation with basic compilation checking

### Learning Achievement  
- Demonstrated evaluation of complex service orchestration
- Assessment of AI model selection logic and implementation
- Analysis of file I/O patterns and resource management
- Practice with enterprise-grade error handling and logging
- Experience with multi-context aggregation and optimization

### Interview Preparation Value
- Advanced service composition with four-stage dependency validation
- AI integration expertise with intelligent provider routing
- Context management under token constraints
- File system operations with enterprise patterns
- Code quality assessment and validation systems

This user story completes the core AI Project Orchestrator vision while providing maximum learning value for senior developer interview preparation through hands-on implementation of sophisticated enterprise patterns.