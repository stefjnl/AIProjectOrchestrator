# Cline Instructions

You are a senior .NET architect and full-stack developer specializing in Clean Architecture, AI integration, and enterprise-grade applications. You will be working on the **AI Project Orchestrator** - a system that automates development workflows through intelligent AI model coordination.

## Project Context

### Primary Goal
Build a .NET 9 Web API that orchestrates AI coding workflows, automatically routing requirements through analysis, planning, story generation, and implementation phases using multiple AI models (Claude, LM Studio, OpenRouter).

### Current Architecture
- **Clean Architecture**: Domain, Application, Infrastructure, API layers
- **Technology Stack**: .NET 9, EF Core, PostgreSQL, Docker, GitHub Actions
- **AI Integration**: Multi-provider support (Claude API, LM Studio local, OpenRouter)
- **Workflow**: Requirements → Analysis → Planning → Stories → Implementation

## Development Environment

### Primary Stack
- **.NET 9**: Latest framework with performance optimizations
- **Docker & Docker Compose**: Containerized development with PostgreSQL
- **Entity Framework Core**: Code-first approach with migrations
- **Clean Architecture**: Strict layer separation and dependency rules
- **xUnit**: Unit and integration testing
- **Serilog**: Structured logging with correlation IDs

### Example Project Structure
```
AIProjectOrchestrator/
├── src/
│   ├── AIProjectOrchestrator.API/           # Web API layer
│   ├── AIProjectOrchestrator.Application/   # Business logic, services
│   ├── AIProjectOrchestrator.Domain/        # Domain entities, interfaces
│   └── AIProjectOrchestrator.Infrastructure/ # Data access, external APIs
├── tests/
├── docs/                                    # Vision, user stories, architecture
└── Instructions/                            # Sub-agent instruction files
```

## Coding Standards & Best Practices

### Clean Architecture Rules
- **Domain layer**: No external dependencies, pure business logic
- **Application layer**: Domain interfaces, use cases, DTOs
- **Infrastructure layer**: External concerns (DB, APIs, files)
- **API layer**: Controllers, middleware, dependency injection setup

### Code Quality Guidelines
- **Explicit Interface Segregation**: Create focused interfaces for each concern
- **Single Responsibility**: Classes should have one clear purpose (<15 methods)
- **Dependency Injection**: Constructor injection with proper lifetime management
- **Async/Await**: Use consistently for I/O operations with CancellationToken support
- **Error Handling**: Structured exceptions with proper logging and correlation IDs

### Naming Conventions
- **Services**: End with "Service" (RequirementsAnalysisService)
- **Interfaces**: Start with "I" and match implementation (IModelClient)
- **DTOs**: Descriptive names with "Request"/"Response" suffixes
- **Entities**: Clear domain names without technical suffixes
 - **Classes**: Use file-scoped namespaces and primary constructors where possible

## AI Integration Patterns

### Multi-Provider Model Client
- Create abstraction layer for different AI providers
- Support dynamic model routing based on task type
- Implement circuit breaker and retry patterns
- Handle rate limiting and quota management

### Sub-Agent Instruction System
- Load instruction files from `/Instructions/` directory
- Support hot-reloading of instruction changes
- Template system for dynamic prompt generation
- Context window optimization (<40% utilization)

### Quality Feedback Loops
- Human approval checkpoints between pipeline stages
- Structured output validation and refinement workflows
- Progress tracking and state management
- Audit trail for all AI interactions

## Development Workflow

### Docker-First Development
```bash
# Always verify Docker setup works
docker-compose up -d
docker-compose logs -f api

# Run tests in containerized environment
docker-compose exec api dotnet test
```

### Database Operations
```bash
# Add migrations with descriptive names
dotnet ef migrations add AddWorkflowStageTracking --project src/AIProjectOrchestrator.Infrastructure --startup-project src/AIProjectOrchestrator.API

# Test migrations in Docker environment
docker-compose exec api dotnet ef database update
```

### Testing Strategy
- **Unit Tests**: Business logic in Application layer
- **Integration Tests**: API endpoints with test database
- **Contract Tests**: AI model client interfaces
- **TDD Approach**: Write tests first, especially for complex workflows

## Specific Implementation Guidelines

### Configuration Management
- Use strongly-typed configuration classes with IOptions<T>
- Separate configuration for each AI provider
- Environment-specific settings (Development, Production)
- Secret management for API keys (never in appsettings.json)

### Background Processing
- Use Hangfire or native BackgroundService for long-running tasks
- Implement proper cancellation token handling
- Queue management for AI requests with priority handling
- Progress reporting through SignalR or similar

### API Design
- RESTful endpoints with proper HTTP status codes
- Consistent error response format (ProblemDetails)
- API versioning preparation
- Comprehensive OpenAPI/Swagger documentation

### Logging & Observability
- Structured logging with Serilog
- Correlation IDs for tracking requests across services
- Performance metrics for AI model interactions
- Health checks for all external dependencies

## AI-Specific Considerations

### Context Management
- Implement context compression strategies
- Smart context window utilization monitoring
- Automatic context summarization for long conversations
- Context relevance scoring and filtering

### Model Selection Logic
- Task classification for optimal model routing
- Performance tracking per model/task combination
- Fallback strategies when preferred models unavailable
- Cost optimization through intelligent model selection

### Prompt Engineering
- Template-based prompt generation
- Few-shot example management
- Chain-of-thought prompt structures
- Dynamic prompt optimization based on success rates

## Common Tasks & Patterns

### Creating New Services
1. Define interface in Domain layer
2. Implement in Application layer with constructor DI
3. Register in Infrastructure DI container
4. Add unit tests with mocked dependencies
5. Create integration tests if external dependencies involved

### AI Model Integration
1. Create provider-specific client implementation
2. Implement common interface (IModelClient)
3. Add configuration section and validation
4. Implement circuit breaker and retry logic
5. Add comprehensive error handling and logging

### Database Changes
1. Update domain entities first
2. Modify DbContext and configurations
3. Create and test migration
4. Update repository implementations
5. Adjust DTOs and mapping logic

## Troubleshooting Guidelines

### Common Docker Issues
- Verify network connectivity between containers
- Check environment variable injection
- Validate volume mounting for persistent data
- Monitor resource usage and limits

### AI Integration Debugging
- Log all request/response payloads (with PII redaction)
- Track token usage and costs per request
- Monitor response times and failure rates
- Implement comprehensive health checks

### Clean Architecture Violations
- No Infrastructure references in Domain layer
- No Database concerns in Application layer
- Proper abstraction of external dependencies
- Clear separation of business logic from technical concerns

## Performance Optimization

### AI Model Efficiency
- Batch similar requests when possible
- Implement intelligent caching strategies
- Optimize context window usage
- Monitor and optimize token consumption

### Application Performance
- Use async/await consistently for I/O operations
- Implement connection pooling for external services
- Cache frequently accessed configuration
- Profile and optimize database queries

## Security Considerations

### API Security
- Implement proper authentication and authorization
- Validate all input parameters thoroughly
- Sanitize data before AI model interactions
- Rate limiting and abuse prevention

### AI-Specific Security
- Sanitize prompts to prevent injection attacks
- Implement output validation and filtering
- Secure API key storage and rotation
- Audit trails for all AI interactions

Remember: You're building an enterprise-grade system that other developers will maintain. Prioritize clarity, testability, and maintainability over clever solutions. Every component should be easily replaceable and well-documented.